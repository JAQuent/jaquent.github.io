<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bayesian Stats on Jörn Alexander Quent&#39;s notebook</title>
    <link>https://jaquent.github.io/tags/bayesian-stats/</link>
    <description>Recent content in Bayesian Stats on Jörn Alexander Quent&#39;s notebook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://jaquent.github.io/tags/bayesian-stats/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Finding a U-shape with Bayesian interrupted regression</title>
      <link>https://jaquent.github.io/2021/02/finding-a-u-shape-with-bayesian-interrupted-regression/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jaquent.github.io/2021/02/finding-a-u-shape-with-bayesian-interrupted-regression/</guid>
      <description>The outset of the problem In one of my project, I’d like to show that there is a U-shape relationship between two variables. The traditional way to do this would be to fit a quadratic model and test whether the quadratic term is different from zero. However, Simonsohn (2018) among other correctly points out that evidence for a quadratic fit is not enough and there might be situations where the quadratic term is not zero but there is no true u-shape.</description>
    </item>
    
    <item>
      <title>The priors that I use for logistic regression now</title>
      <link>https://jaquent.github.io/2021/01/the-priors-that-i-use-for-logistic-regression-now/</link>
      <pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://jaquent.github.io/2021/01/the-priors-that-i-use-for-logistic-regression-now/</guid>
      <description>Problem In my power simulation of the U-shape experiment, I noticed that the suggested priors (click here) actually do not work very well for Bayes Factor (BF) analysis as they are too flat and hence BF are too conservative. That is because uniform or very flat priors lead to less evidence in favour of the alternative hypothesis.</description>
    </item>
    
    <item>
      <title>Bayesian sequential designs are superior</title>
      <link>https://jaquent.github.io/2020/07/bayesian-sequential-designs-are-superior/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://jaquent.github.io/2020/07/bayesian-sequential-designs-are-superior/</guid>
      <description>This post is based on a short talk that I gave at the MRC CBU on the 29 July 2020 for a session on statistical power. The slides of presentation can be found in my GitHub repository. This repository also includes the data and the scripts that were used to run the simulations and to create the figures.</description>
    </item>
    
    <item>
      <title>Comparing different methods to calculate Bayes factors for a simple model</title>
      <link>https://jaquent.github.io/2020/07/comparing-different-methods-to-calculate-bayes-factors-for-a-simple-model/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://jaquent.github.io/2020/07/comparing-different-methods-to-calculate-bayes-factors-for-a-simple-model/</guid>
      <description>Introduction Comparing the four BF methods Evidence for null hypothesis: brms vs. ttestBF() How much more conservative is the bmrs approach? Directed vs. non-directed hypothesis Conclusion Introduction In this post, I’d like to examine how different ways to calcualte Bayes factors (BF) compare with each other for a simple model.</description>
    </item>
    
  </channel>
</rss>
